{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Welcome!\n",
                "\n",
                "This is a daily report, on the performance of specific exchange rates. It is to be ran at market close, to determine potential courses of action."
            ],
            "metadata": {
                "azdata_cell_guid": "0a6f621c-0b64-47ce-a014-9f06b7328673"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "###Daily report\r\n",
                "\r\n",
                "import pyodbc\r\n",
                "from datetime import datetime\r\n",
                "import pandas as pd\r\n",
                "import yfinance as yf\r\n",
                "import requests\r\n",
                "import pandas_ta as ta\r\n",
                "import pyodbc\r\n",
                "\r\n",
                "global dictdate\r\n",
                "dictdate = {\r\n",
                "    \"AXS\" : \"2020-11-04\",\r\n",
                "    \"ENS\" : \"2021-11-09\",\r\n",
                "    \"NEXO\": \"2018-05-01\",\r\n",
                "    \"DOT\" : \"2020-08-20\",\r\n",
                "    \"XRP\" : \"2017-11-09\",\r\n",
                "    \"ETH\" : \"2017-11-09\",\r\n",
                "    \"ARB11841\" : \"2023-03-23\",\r\n",
                "    \"TIA22861\" : \"2023-10-31\",\r\n",
                "    \"ADA\" : \"2017-11-09\",\r\n",
                "    \"HBAR\" : \"2019-09-17\",\r\n",
                "    \"SOL\" : \"2020-04-10\",\r\n",
                "    \"NEAR\" : \"2020-10-14\",\r\n",
                "    \"RUNE\" : \"2019-07-23\",\r\n",
                "    \"FTM\" : \"2018-10-30\",\r\n",
                "    \"LINK\" : \"2017-11-09\",\r\n",
                "    \"BCH\" : \"2017-11-09\",\r\n",
                "    \"AVAX\" : \"2020-07-13\",\r\n",
                "    \"ORDI\" : \"2023-05-08\",\r\n",
                "    \"OP\" : \"2022-03-14\",\r\n",
                "    \"DOGE\" : \"2017-11-09\",\r\n",
                "    \"BONK\" : \"2022-12-30\",\r\n",
                "    \"MATIC\" : \"2019-04-28\",\r\n",
                "    \"AI\" : \"2021-09-22\",\r\n",
                "    \"LTC\" : \"2014-09-17\",\r\n",
                "    \"BNB\" : \"2017-11-09\",\r\n",
                "    \"ETC\" : \"2017-11-09\",\r\n",
                "    \"JUP\" : \"2017-11-09\",\r\n",
                "    \"XMR\" : \"2017-11-09\",\r\n",
                "    \"FIL\" : \"2017-12-13\",\r\n",
                "    \"DYDX\" : \"2021-11-08\",\r\n",
                "    \"ATOM\" : \"2019-03-14\",\r\n",
                "    \"EOS\" : \"2017-11-09\",\r\n",
                "    \"TRB\" : \"2019-11-19\",\r\n",
                "    \"FTM\" : \"2018-10-30\",\r\n",
                "    \"JTO\" : \"2023-12-07\",\r\n",
                "    \"GALA\" : \"2020-09-18\",\r\n",
                "    \"BLUR\" : \"2023-02-14\"\r\n",
                "}\r\n",
                "\r\n",
                "def dataImport(token):\r\n",
                "\r\n",
                "    global creation\r\n",
                "    global current\r\n",
                "    global activetime\r\n",
                "\r\n",
                "    if token in dictdate.keys():\r\n",
                "        datestr = dictdate[token]\r\n",
                "    elif token == \"ARB\":\r\n",
                "        datestr = \"2023-03-23\"\r\n",
                "        token = \"ARB11841\"\r\n",
                "    elif token == \"TIA\":\r\n",
                "        datestr = \"2023-10-31\"\r\n",
                "        token = \"TIA22861\"\r\n",
                "    else:\r\n",
                "        datestr = input(\"Not in our database! Enter a date (YYYY-MM-DD): \")\r\n",
                "        print (\"Don't forget to add the date to the dictionary!\")\r\n",
                "\r\n",
                "    creation = datetime.strptime(datestr, \"%Y-%m-%d\")\r\n",
                "    current = datetime.today()\r\n",
                "    activetime = (current - creation).days\r\n",
                "\r\n",
                "    # Connection parameters - replace with your values\r\n",
                "    server = 'LAPTOP-7NBR16RS\\SQLEXPRESS01' \r\n",
                "    database = 'models'\r\n",
                "    cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + database + ';Trusted_Connection=yes;')\r\n",
                "\r\n",
                "    cursor = cnxn.cursor()\r\n",
                "\r\n",
                "    # Set up the table and the auto procedure\r\n",
                "\r\n",
                "    try:\r\n",
                "        # It's more common to use separate execute calls for each SQL statement, but here's a try for batch execution\r\n",
                "        cursor.execute(f\"\"\"\r\n",
                "            IF OBJECT_ID('{token}daily', 'P') IS NOT NULL\r\n",
                "                DROP PROCEDURE {token}daily;\r\n",
                "        \"\"\")\r\n",
                "\r\n",
                "        cursor.execute(f\"\"\"            \r\n",
                "            IF OBJECT_ID('{token}HistoricalPrices', 'U') IS NOT NULL\r\n",
                "                DROP TABLE {token}HistoricalPrices;\r\n",
                "        \"\"\")\r\n",
                "\r\n",
                "        cursor.execute(f\"\"\"\r\n",
                "            CREATE TABLE {token}HistoricalPrices (\r\n",
                "                [Date] DATE,\r\n",
                "                [Open] DECIMAL(10, 6),\r\n",
                "                [High] DECIMAL(10, 6),\r\n",
                "                [Low] DECIMAL(10, 6),\r\n",
                "                [Close] DECIMAL(10, 6),\r\n",
                "                [Adj Close] DECIMAL(10, 6),\r\n",
                "                [Volume] BIGINT\r\n",
                "            );\r\n",
                "        \"\"\")\r\n",
                "\r\n",
                "        cursor.execute(f\"\"\"\r\n",
                "            CREATE PROCEDURE {token}daily \r\n",
                "                @dates DATE,\r\n",
                "                @opens DECIMAL(10, 6),\r\n",
                "                @highs DECIMAL(10, 6),\r\n",
                "                @lows DECIMAL(10, 6),\r\n",
                "                @closes DECIMAL(10, 6),\r\n",
                "                @adjcloses DECIMAL(10, 6),\r\n",
                "                @volumes BIGINT\r\n",
                "            AS BEGIN\r\n",
                "                INSERT INTO {token}HistoricalPrices (\r\n",
                "                    [Date],\r\n",
                "                    [Open],\r\n",
                "                    [High],\r\n",
                "                    [Low],\r\n",
                "                    [Close],\r\n",
                "                    [Adj Close],\r\n",
                "                    [Volume]\r\n",
                "                )\r\n",
                "                VALUES (\r\n",
                "                    @dates,\r\n",
                "                    @opens,\r\n",
                "                    @highs,\r\n",
                "                    @lows,\r\n",
                "                    @closes,\r\n",
                "                    @adjcloses,\r\n",
                "                    @volumes\r\n",
                "                );\r\n",
                "            END;\r\n",
                "        \"\"\")\r\n",
                "\r\n",
                "        cnxn.commit()\r\n",
                "\r\n",
                "    except Exception as e:\r\n",
                "        print(f'Preliminary SQL execution failed: {e}')\r\n",
                "        cursor.close()\r\n",
                "        cnxn.close()\r\n",
                "        return\r\n",
                "\r\n",
                "\r\n",
                "    # Read data from Yahoo! Finance\r\n",
                "\r\n",
                "    today_date = datetime.today().strftime('%Y-%m-%d')\r\n",
                "\r\n",
                "    df = yf.download(f\"{token}-USD\", start=datestr, end=today_date)\r\n",
                "\r\n",
                "    df.reset_index(inplace=True)\r\n",
                "\r\n",
                "    # Loop through the DataFrame and insert each row\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        cursor.execute(f\"EXEC {token}daily @dates = ?, @opens = ?, @highs = ?, @lows = ?, @closes = ?, @adjcloses = ?, @volumes = ?\", \r\n",
                "                       row['Date'], row['Open'], row['High'], row['Low'], row['Close'], row['Adj Close'], row['Volume'])\r\n",
                "\r\n",
                "    # Commit the transaction\r\n",
                "    try :\r\n",
                "        cnxn.commit()\r\n",
                "    except:\r\n",
                "        print ('Data import failed!')\r\n",
                "\r\n",
                "    # Close the connection\r\n",
                "    cursor.close()\r\n",
                "    cnxn.close()\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "# Function to calculate the daily percentage change in price and volume\r\n",
                "def calculate_price_volume_change(df):\r\n",
                "    # Calculate daily percentage change in price\r\n",
                "    df['Price_Change'] = df['Close'].pct_change() * 100\r\n",
                "    \r\n",
                "    # Calculate daily percentage change in volume\r\n",
                "    df['Volume_Change'] = df['Volume'].pct_change() * 100\r\n",
                "    \r\n",
                "    return df\r\n",
                "\r\n",
                "# Function to identify potential pump-and-dump activities based on predefined thresholds\r\n",
                "def identify_potential_pump_and_dump(df, price_change_threshold, volume_change_threshold):\r\n",
                "    # Identify potential pump-and-dump activities\r\n",
                "    df['Potential_Pump_and_Dump'] = (df['Price_Change'] > price_change_threshold) & (df['Volume_Change'] > volume_change_threshold)\r\n",
                "    \r\n",
                "    return df\r\n",
                "\r\n",
                "# Function to conduct market context analysis incorporating pump-and-dump analysis\r\n",
                "def conduct_market_context_analysis(df):\r\n",
                "    # Initialize market context column\r\n",
                "    df['Market_Context'] = 'Neutral'\r\n",
                "    \r\n",
                "    # Update market context based on pump-and-dump analysis\r\n",
                "    df.loc[df['Potential_Pump_and_Dump'], 'Market_Context'] = 'Potential Pump-and-Dump'\r\n",
                "    \r\n",
                "    return df\r\n",
                "\r\n",
                "def emotional(token, index):\r\n",
                "\r\n",
                "    pd.set_option('display.max_columns', None)\r\n",
                "\r\n",
                "    cnxn = connectionEst()\r\n",
                "\r\n",
                "    query = f\"SELECT * FROM {token}HistoricalPrices\"\r\n",
                "    df = pd.read_sql(query, cnxn)\r\n",
                "\r\n",
                "    if token == \"ARB\":\r\n",
                "        token = \"ARB11841\"\r\n",
                "\r\n",
                "    if token == \"TIA\":\r\n",
                "        token = \"TIA22861\"\r\n",
                "\r\n",
                "\r\n",
                "    # Define thresholds for identifying potential pump-and-dump activities\r\n",
                "    price_change_threshold = 10  # Percentage change in price threshold\r\n",
                "    volume_change_threshold = 20  # Percentage change in volume threshold\r\n",
                "\r\n",
                "    query = f\"SELECT * FROM {token}HistoricalPrices\"\r\n",
                "    df = pd.read_sql(query, cnxn)\r\n",
                "\r\n",
                "    # Calculate price and volume changes\r\n",
                "    df = calculate_price_volume_change(df)\r\n",
                "\r\n",
                "    # Identify potential pump-and-dump activities\r\n",
                "    df = identify_potential_pump_and_dump(df, price_change_threshold, volume_change_threshold)\r\n",
                "\r\n",
                "    # Conduct market context analysis\r\n",
                "    df = conduct_market_context_analysis(df)\r\n",
                "\r\n",
                "    df['Index'] = index\r\n",
                "\r\n",
                "    # Display the DataFrame with updated market context\r\n",
                "    return df.tail(1).sort_values(by='Date', ascending = False)\r\n",
                "\r\n",
                "def connectionEst():\r\n",
                "\r\n",
                "    global cnxn\r\n",
                "\r\n",
                "    # Connection parameters - replace with your values\r\n",
                "    server = 'LAPTOP-7NBR16RS\\SQLEXPRESS01' \r\n",
                "    database = 'models'\r\n",
                "    cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + database + ';Trusted_Connection=yes;')\r\n",
                "    return cnxn\r\n",
                "\r\n",
                "\r\n",
                "def calculate_technical_indicators(df, index, period=20, num_std=2):\r\n",
                "    # Assuming df has 'Close', 'High', and 'Low' columns\r\n",
                "\r\n",
                "    # Convert 'Date' to datetime and set as index\r\n",
                "\r\n",
                "    # Calculate Moving Averages\r\n",
                "    df['SMA_20'] = ta.sma(df['Close'], length=period)\r\n",
                "    df['EMA_20'] = ta.ema(df['Close'], length=period)\r\n",
                "   \r\n",
                "    # Bollinger Bands\r\n",
                "    df['SMA'] = df['Close'].rolling(window=period).mean()  # Simple Moving Average\r\n",
                "    df['STD'] = df['Close'].rolling(window=period).std()  # Standard Deviation\r\n",
                "    df['Upper_Band'] = df['SMA'] + (df['STD'] * num_std)\r\n",
                "    df['Lower_Band'] = df['SMA'] - (df['STD'] * num_std)\r\n",
                "\r\n",
                "    # RSI\r\n",
                "    df['RSI_14'] = ta.rsi(df['Close'], length=14)\r\n",
                "\r\n",
                "    # MACD\r\n",
                "    macd = ta.macd(df['Close'], fast=12, slow=26, signal=9)\r\n",
                "    try:\r\n",
                "        df['MACD'] = macd['MACD_12_26_9']\r\n",
                "        df['MACD_Signal'] = macd['MACDs_12_26_9']\r\n",
                "        df['MACD_Histogram'] = macd['MACDh_12_26_9']\r\n",
                "    except:\r\n",
                "        df['MACD'] = \"Not available\"\r\n",
                "        df['MACD_Signal'] = \"Not available\"\r\n",
                "        df['MACD_Histogram'] = \"Not available\"\r\n",
                "    \r\n",
                "    # Identifying bullish or bearish trends\r\n",
                "    try:\r\n",
                "        df['Trend'] = 'Neutral'\r\n",
                "        df.loc[df['Close'] > df['SMA_20'], 'Trend'] = 'Bullish'\r\n",
                "        df.loc[df['Close'] < df['SMA_20'], 'Trend'] = 'Bearish'\r\n",
                "    except:\r\n",
                "        df['Trend'] = \"Not available\"\r\n",
                "\r\n",
                "\r\n",
                "    # Volume confirmation\r\n",
                "    df['Volume_Confirmation'] = False\r\n",
                "    df.loc[(df['Volume'].shift(1) < df['Volume']) & \r\n",
                "           ((df['Trend'] == 'Bullish') & (df['Close'] > df['Close'].shift(1)) | \r\n",
                "            (df['Trend'] == 'Bearish') & (df['Close'] < df['Close'].shift(1))), 'Volume_Confirmation'] = True\r\n",
                "\r\n",
                "    # Bollinger Bands for volatility and price position\r\n",
                "    df['Bollinger_Signal'] = 'Neutral'\r\n",
                "    df.loc[df['Close'] > df['Upper_Band'], 'Bollinger_Signal'] = 'Overbought'\r\n",
                "    df.loc[df['Close'] < df['Lower_Band'], 'Bollinger_Signal'] = 'Oversold'\r\n",
                "\r\n",
                "    # RSI for momentum\r\n",
                "    df['RSI_Signal'] = 'Neutral'\r\n",
                "    df.loc[df['RSI_14'] > 70, 'RSI_Signal'] = 'Overbought'\r\n",
                "    df.loc[df['RSI_14'] < 30, 'RSI_Signal'] = 'Oversold'\r\n",
                "\r\n",
                "    # MACD for trend changes\r\n",
                "    df['MACD_Signal_Char'] = 'Neutral'\r\n",
                "    df.loc[df['MACD'] > df['MACD_Signal'], 'MACD_Signal_Char'] = 'Bullish'\r\n",
                "    df.loc[df['MACD'] < df['MACD_Signal'], 'MACD_Signal_Char'] = 'Bearish'\r\n",
                "\r\n",
                "    # Price action relative to moving averages for potential reversals\r\n",
                "    try:\r\n",
                "        df['Price_MA_Relation'] = 'Neutral'\r\n",
                "        df.loc[(df['Close'] > df['SMA_20']) & (df['Close'].shift(1) < df['SMA_20'].shift(1)), 'Price_MA_Relation'] = 'Potential Reversal Up'\r\n",
                "        df.loc[(df['Close'] < df['SMA_20']) & (df['Close'].shift(1) > df['SMA_20'].shift(1)), 'Price_MA_Relation'] = 'Potential Reversal Down'\r\n",
                "    except:\r\n",
                "         df['Price_MA_Relation'] = 'Not available'\r\n",
                "\r\n",
                "    try:\r\n",
                "        df['Trend_Volume'] = 'Neutral'\r\n",
                "        df.loc[(df['Close'] > df['SMA_20']) & (df['Close'] > df['EMA_20']) & (df['Volume'].diff() > 0), 'Trend_Volume'] = 'Bullish with Volume Increase'\r\n",
                "        df.loc[(df['Close'] < df['SMA_20']) & (df['Close'] < df['EMA_20']) & (df['Volume'].diff() > 0), 'Trend_Volume'] = 'Bearish with Volume Increase'\r\n",
                "    except:\r\n",
                "        df['Trend_Volume'] = 'Not available'\r\n",
                "    \r\n",
                "    # Bollinger Bands and Volume for Market Extremes\r\n",
                "    df['Bollinger_Volume'] = 'Neutral'\r\n",
                "    df.loc[(df['Close'] > df['Upper_Band']) & (df['Volume'].diff() > 0), 'Bollinger_Volume'] = 'Overbought with Volume Increase'\r\n",
                "    df.loc[(df['Close'] < df['Lower_Band']) & (df['Volume'].diff() > 0), 'Bollinger_Volume'] = 'Oversold with Volume Increase'\r\n",
                "    \r\n",
                "    # RSI and Volume for Momentum Confirmation\r\n",
                "    df['RSI_Volume'] = 'Neutral'\r\n",
                "    df.loc[(df['RSI_14'] > 70) & (df['Volume'].diff() > 0), 'RSI_Volume'] = 'Overbought with High Volume'\r\n",
                "    df.loc[(df['RSI_14'] < 30) & (df['Volume'].diff() > 0), 'RSI_Volume'] = 'Oversold with High Volume'\r\n",
                "    \r\n",
                "    # MACD, Volume, and Market Reversals\r\n",
                "    df['MACD_Signal_Volume'] = 'Neutral'\r\n",
                "    df.loc[(df['MACD'] > df['MACD_Signal']) & (df['Volume'].diff() > 0), 'MACD_Signal_Volume'] = 'Bullish Crossover with Volume Increase'\r\n",
                "    df.loc[(df['MACD'] < df['MACD_Signal']) & (df['Volume'].diff() > 0), 'MACD_Signal_Volume'] = 'Bearish Crossover with Volume Increase'\r\n",
                "    \r\n",
                "    # Contextual Analysis Based on Historical Highs/Lows\r\n",
                "    try:\r\n",
                "        df['Market_Context'] = 'Neutral'\r\n",
                "        df.loc[(df['Close'] > df['SMA_20']) & (df['Close'] > df['EMA_20']) & (df['Close'] < df['Low'].min() * 1.10), 'Market_Context'] = 'Bullish Near Historical Lows'\r\n",
                "        df.loc[(df['Close'] < df['SMA_20']) & (df['Close'] < df['EMA_20']) & (df['Close'] > df['High'].max() * 0.90), 'Market_Context'] = 'Bearish Near Historical Highs'\r\n",
                "    except:\r\n",
                "        df['Market_Context'] = 'Not available'\r\n",
                "\r\n",
                "    df ['Index'] = index\r\n",
                "\r\n",
                "    return df.tail(1).sort_values(by='Date', ascending = False)\r\n",
                "\r\n",
                "\r\n",
                "def technical(token, index):\r\n",
                "\r\n",
                "    pd.set_option('display.max_columns', None)\r\n",
                "\r\n",
                "    cnxn = connectionEst()\r\n",
                "\r\n",
                "    query = f\"SELECT * FROM {token}HistoricalPrices\"\r\n",
                "    df = pd.read_sql(query, cnxn)\r\n",
                "\r\n",
                "    if df.empty:\r\n",
                "        return\r\n",
                "\r\n",
                "    return calculate_technical_indicators(df, index)\r\n",
                "\r\n",
                "\r\n",
                "emotionalFrame = None\r\n",
                "technicalFrame = None\r\n",
                "appendix = None\r\n",
                "new = None\r\n",
                "index = None\r\n",
                "\r\n",
                "for k in dictdate.keys():\r\n",
                "\r\n",
                "    dataImport(k)\r\n",
                "\r\n",
                "for k in dictdate.keys():\r\n",
                "\r\n",
                "    if emotionalFrame is None:\r\n",
                "        new = emotional (k, k)\r\n",
                "        emotionalFrame = new\r\n",
                "    else:\r\n",
                "        appendix = emotional(k, k)\r\n",
                "        emotionalFrame = pd.concat((emotionalFrame, appendix), axis = 0)\r\n",
                "\r\n",
                "for k in dictdate.keys():\r\n",
                "\r\n",
                "    if technicalFrame is None:\r\n",
                "        new = technical(k, k)\r\n",
                "        technicalFrame = new\r\n",
                "    else:\r\n",
                "        appendix = technical(k, k)\r\n",
                "        technicalFrame = pd.concat((technicalFrame, appendix), axis = 0)\r\n",
                "\r\n",
                "complete = pd.merge(emotionalFrame, technicalFrame, on = 'Index')\r\n",
                "\r\n",
                "complete\r\n",
                "\r\n",
                "    "
            ],
            "metadata": {
                "azdata_cell_guid": "a21a1e14-70c5-4b94-a2aa-379546be22b3",
                "language": "python",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}